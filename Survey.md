### Surveys 

#### LLM Backdoors
- [2025/02] **A Survey on Backdoor Threats in Large Language Models (LLMs): Attacks, Defenses, and Evaluations** - [arXiv](https://arxiv.org/abs/2502.05224)
- [2024/06] **A Survey of Recent Backdoor Attacks and Defenses in Large Language Models** - [arXiv](https://arxiv.org/abs/2406.06852)
- [2025/12] **Backdoor Attacks and Countermeasures in Natural Language Processing Models: A Comprehensive Security Review** - [arXiv](https://arxiv.org/abs/2309.06055)


#### Red Teaming
- [2025/03] **Building Safe GenAI Applications: An End-to-End Overview of Red Teaming for Large Language Models** - [arXiv](https://arxiv.org/abs/2503.01742)
- [2025/04] **Against The Achillesâ€™ Heel: A Survey on Red Teaming for Generative Models** - [JAIR](https://www.jair.org/index.php/jair/article/view/17654)

#### LLM Security
- [2025/05] **LLM Security: Vulnerabilities, Attacks, Defenses, and Countermeasures** - [arXiv](https://arxiv.org/abs/2505.01177)
- [2025/05] **Attack and Defense Techniques in Large Language Models: A Survey and New Perspectives** - [arXiv](https://arxiv.org/abs/2505.00976)

#### Attacks/Defenses
- [2025/05] **A Survey of Attacks on Large Language Models** - [arXiv](https://arxiv.org/abs/2505.12567)
- [2025/06] **From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem** - [arXiv](https://arxiv.org/abs/2506.15170)

#### Threats & Misuse
- [2025/05] **Security Concerns for Large Language Models: A Survey** - [arXiv](https://arxiv.org/abs/2505.18889)

#### Data/Model Poisoning
- [2025/06] **A Systematic Review of Poisoning Attacks Against Large Language Models** - [arXiv](https://arxiv.org/abs/2506.06518)

#### Model Extraction
- [2025/06] **A Survey on Model Extraction Attacks and Defenses for Large Language Models** - [arXiv](https://arxiv.org/abs/2506.22521)

#### Agent Threat Model
- [2025/05] **Forewarned is Forearmed: A Survey on Large Language Model-based Agents in Autonomous Cyberattacks** - [arXiv](https://arxiv.org/abs/2505.12786)
- [2025/06] **From Prompt Injections to Protocol Exploits: Threats in LLM-Powered AI Agents Workflows** - [arXiv](https://arxiv.org/abs/2506.23260)
- [2025/06] **A Survey of LLM-Driven AI Agent Communication: Protocols, Security Risks, and Defense Countermeasures** - [arXiv](https://arxiv.org/abs/2506.19676)
- [2025/03] **A Survey on Trustworthy LLM Agents: Threats and Countermeasures** - [arXiv](https://arxiv.org/abs/2503.09648)

#### Data Security
- [2025/08] **A Survey on Data Security in Large Language Models** - [arXiv](https://arxiv.org/abs/2508.02312)

#### Prompt Injection Threat Model
- [2025/09] **A Threat Model of Prompt-Based Attacks for Securing LLMs** - [arXiv](https://arxiv.org/abs/2509.04615)

#### Cross-Domain Overviews
- [2025/04] **Exploring the Role of Large Language Models in Cybersecurity: A Systematic Survey** - [arXiv](https://arxiv.org/abs/2504.15622)
- [2025/09] **Large Language Models in Cybersecurity: A Survey of Applications, Vulnerabilities, and Defense Techniques** - [MDPI](https://www.mdpi.com/2673-2688/6/9/216)

#### SoK (Systematization of Knowledge)
- [2025/05] **SoK: Large Language Models in Security Code Review and Testing** - [OpenReview](https://openreview.net/forum?id=hMkoe4C44D)
- [2025/06] **SoK: Evaluating Jailbreak Guardrails for Large Language Models** - [arXiv](https://arxiv.org/abs/2506.10597)
- [2025/08] **SoK: Large Language Model-Generated Textual Phishing** - [arXiv](https://arxiv.org/abs/2508.21457)
