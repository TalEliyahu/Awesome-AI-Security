## Multi-Agent Security Threats - Not complete 

| Challenge | TL;DR |
|---|---|
| **Privacy vulnerabilities and Disinformation** | Interacting agents often hold private information essential to their tasks, yet must juggle multiple contexts and decide dynamically what to share—and with whom. They’re vulnerable to a range of worst-case exploits, from distributed (semantic) inference attacks and jailbreaks to other context-targeting hacks. In multi-agent systems, privacy breaches can spread rapidly and may be indistinguishable from intentional disinformation. |
| **Steganography and secret collusion** | Although agent communications may appear as ordinary natural language, they can conceal secret steganography - masking private data, enabling covert collusion, or facilitating deception - and thus evade oversight by standard security monitoring. Such operations could enable agents to coordinate secretly over prolonged periods of time, therefore enable new forms of persistent threats. |
| **Adversarial stealth** | Adversarial behaviour might be hard to detect and pose unacceptable performance tradeoffs to counter strategically without disrupting cooperation or emergence. This includes whitebox undetectability if behaviour is encoded in encrypted backdoors. |
| **Exploitation** | Agents in heterogeneous networks could exploit asymmetries in compute, data, or network contributions - free-riding, or resource monopolization - to stall learning, skew incentives, and erode cooperation. |
| **Swarm attacks** | Coordinated fleets of AI agents can combine their resources to overwhelm targets - paralleling DDoS and brigading tactics - to bypass assumptions of single - agent limits, collaboratively probe for new vulnerabilities, and aggregate partial inferences into full exploits, vastly amplifying attack potency. |
| **Heterogeneous attacks** | Adversaries combine multiple “safe” agents with complementary skills - delegating subtasks to models with strict safeguards and others with looser constraints - to bypass defenses, significantly increasing attack success rates while making detection and attribution across diffuse agent networks exceedingly difficult. |
| **Oversight attacks** | Misaligned agents may be aware of security measures and actively try to undermine them - this could be done using stealth, or by attacking or circumventing overseers. In multi-agent settings, the use of distributed evasion by collusion or compartmentalisation can make oversight more challenging. |
| **Multi-agent emergence** | Worst-case adversarial behaviour can arise spontaneously from adversarial equilibria arising from multi-agent interaction, without the need for adversarial infiltration or external threats. |
| **Cascade attacks** | Systems of interacting agents may exhibit systemic instabilities, leading to worst-case exploitable cascading weaknesses. This is especially true in edge-of-chaos operations. |
| **Conflict & Social Dilemmas** | Agents’ mixed incentives can drive collective-action failures or escalate competition - automating tragedy-of-the-commons and coercive stratagems at machine speed. |
| **Societal threats** | Advanced AI agents expand the attack surface for automated social engineering: they can generate highly personalized phishing, vishing, and manipulative content at scale, dynamically refine tactics via user feedback, and disperse campaigns across many seemingly independent bots to evade detection - creating cascading disruptions in public trust, financial systems, and political discourse. Such attacks can be low-stakes, meaning they could trigger systemic effects over time like shifting the Overton window. |

