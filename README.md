# Awesome AI Security ğŸ›¡ï¸  

A curated repository of resources, research, tools, and discussions on AI security. This repository consolidates insights from industry reports, academic research, and practical applications.  

---

## Table of Contents  

- [Best Practices & Security Standards](#best-practices--security-standards)  
- [Glossary](#glossary)  
- [Taxonomy](#taxonomy)  
- [Benchmarks](#benchmarks)  
- [Datasets](#datasets)  
- [AI Risk & Incident Databases](#ai-risk--incident-databases)  
- [Additional AI Security Resources](#additional-ai-security-resources)  
- [GitHub Repositories](#github-repositories)  
- [Newsletter](#newsletter)  
- [Conferences & Events](#conferences--events)  
- [Reports & Research](#reports--research)  

---

## Best Practices & Security Standards  

- **[NIST AI Risk Management Framework (AI RMF)](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf)**  
- **[NIST AI Risk Management Framework Playbook](https://airc.nist.gov/airmf-resources/playbook/)**  
- **[MITRE ATLAS](http://atlas.mitre.org)**  
- **[OWASP AI Exchange](https://owaspai.org/docs/ai_security_overview/)**  
- **[OWASP Top 10 for LLM and Generative AI](https://owasp.org/www-project-top-10-for-large-language-model-applications/)**  

---

## Glossary  

- **[NIST - "The Language of Trustworthy AI: An In-Depth Glossary of Terms"](https://airc.nist.gov/glossary/)**  

---

## Taxonomy  

- **[ARC PI Taxonomy](https://github.com/Arcanum-Sec/arc_pi_taxonomy)** â€“ A taxonomy of prompt injection attacks  

---

## Benchmarks  

ğŸ“Œ *(To be added â€“ A curated list of AI security evaluation benchmarks.)*  

---

## Datasets  

ğŸ“Œ *(To be added â€“ Public datasets useful for AI security research and adversarial ML testing.)*  

---

## AI Risk & Incident Databases  

- **[MIT AI Risk Database](https://airisk.mit.edu/)** â€“ A structured repository documenting AI-related risks, incidents, and mitigation strategies to improve governance and security awareness.  
- **[AI Incident Database](https://incidentdatabase.ai/)** â€“ A collection of real-world AI incidents and security failures, helping researchers and practitioners understand past vulnerabilities.  

---

## Additional AI Security Resources  

- **[LLM Security](http://llmsecurity.net)** â€“ Security research on Large Language Models.  
- **[Vinija AI](http://vinija.ai/models/LLM/)** â€“ LLM models and security resources.  

---

## GitHub Repositories  

- **[AI Security & Adversarial ML Reading List](https://github.com/AI-secure/awesome-adversarial-machine-learning)**  

---

## Newsletter  

- **[Adversarial AI Digest](https://www.linkedin.com/newsletters/adversarial-ai-digest-7298813894498598912/)** â€“ A curated newsletter covering AI security research, adversarial threats, governance challenges, and best practices for securing AI systems.  

---

## Conferences & Events  

- **[AI Village (DEF CON)](https://aivillage.org/)** â€“ A community-driven AI security event at DEF CON focused on adversarial AI, ML vulnerabilities, and AI-driven threats.  
- **[Black Hat AI Summit](https://www.blackhat.com/)** â€“ A premier AI security event featuring deep-dive technical talks, research presentations, and expert discussions on securing AI and ML systems.  

ğŸ“Œ *(More to be added â€“ List of key conferences, workshops, and symposiums focused on AI security.)*  

---

## Reports & Research  

ğŸ“Œ *(More to be added â€“ A collection of AI security reports, white papers, and academic studies.)*  

---

ğŸ›¡ï¸ *Contributions are welcome! Feel free to submit PRs with new resources and updates.*  
