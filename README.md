# Awesome AI Security üõ°Ô∏è  

A curated repository of resources, research, tools, and discussions on AI security. This repository consolidates insights from industry reports, academic research, and practical applications.  

---

## Table of Contents  

- [Best Practices & Security Standards](#best-practices--security-standards)  
- [AI Risk & Incident Databases](#ai-risk--incident-databases)  
- [Glossary](#glossary)  
- [Taxonomy](#taxonomy)  
- [Benchmarks](#benchmarks)  
- [Datasets](#datasets)  
- [Additional AI Security Resources](#additional-ai-security-resources)  
- [GitHub Repositories](#github-repositories)  
- [Newsletter](#newsletter)  
- [Conferences & Events](#conferences--events)  
- [Reports & Research](#reports--research)  

---

## Best Practices & Security Standards  

- **[NIST AI Risk Management Framework (AI RMF)](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf)**  
- **[NIST AI Risk Management Framework Playbook](https://airc.nist.gov/airmf-resources/playbook/)**  
- **[MITRE ATLAS](http://atlas.mitre.org)**  
- **[OWASP AI Exchange](https://owaspai.org/docs/ai_security_overview/)**  
- **[OWASP Top 10 for LLM and Generative AI](https://owasp.org/www-project-top-10-for-large-language-model-applications/)**  

---

## AI Risk & Incident Databases  

- **[MIT AI Risk Repository](https://airisk.mit.edu/)** ‚Äì A comprehensive database of over 1,000 AI risks, categorized by cause and domain, providing researchers, policymakers, and developers with a structured understanding of AI threats and mitigation strategies.  
- **[AI Incident Database (AIID)](https://incidentdatabase.ai/)** ‚Äì A public repository cataloging real-world AI failures, risks, and harms, helping researchers, policymakers, and organizations analyze patterns and enhance AI governance.  

---

## Glossary  

- **[NIST - "The Language of Trustworthy AI: An In-Depth Glossary of Terms"](https://airc.nist.gov/glossary/)**  

---

## Taxonomy  

- **[ARC PI Taxonomy](https://github.com/Arcanum-Sec/arc_pi_taxonomy)** ‚Äì A taxonomy of prompt injection attacks  

---

## Benchmarks  

üìå *(To be added ‚Äì A curated list of AI security evaluation benchmarks.)*  

---

## Datasets  

üìå *(To be added ‚Äì Public datasets useful for AI security research and adversarial ML testing.)*  

---

## Additional AI Security Resources  

- **[LLM Security](http://llmsecurity.net)**  
- **[Vinija AI](http://vinija.ai/models/LLM/)**  

---

## GitHub Repositories  

- **[AI Security & Adversarial ML Reading List](https://github.com/AI-secure/awesome-adversarial-machine-learning)**  

---

## Newsletter  

- **[Adversarial AI Digest](https://www.linkedin.com/newsletters/adversarial-ai-digest-7298813894498598912/)**  

---

## Conferences & Events  

- **[AI Village (DEF CON)](https://aivillage.org/)**  
- **[Black Hat AI Summit](https://www.blackhat.com/)**  

üìå *(More to be added ‚Äì List of key conferences, workshops, and symposiums focused on AI security.)*  

---

## Reports & Research  

üìå *(More to be added ‚Äì A collection of AI security reports, white papers, and academic studies.)*  

---

üõ°Ô∏è *Contributions are welcome! Feel free to submit PRs with new resources and updates.*  
